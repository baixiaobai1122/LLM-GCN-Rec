# å¿«é€Ÿå¼€å§‹æŒ‡å— - Phase 1 åŒå›¾LightGCN

## ğŸš€ ä¸€é”®è¿è¡Œ

```bash
cd /home/chuc0007/reccase/LightGCN-PyTorch/code

# æ–¹å¼1ï¼šè¿è¡Œå®Œæ•´pipelineï¼ˆæ¨èï¼‰
python run_phase1.py --dataset amazon-book --epochs 100

# æ–¹å¼2ï¼šè¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆ5ä¸ªepochéªŒè¯ï¼‰
bash quick_test.sh
```

---

## ğŸ“ å·²åˆ›å»ºçš„æ–‡ä»¶

### æ ¸å¿ƒä»£ç ï¼ˆ7ä¸ªæ–‡ä»¶ï¼‰

| æ–‡ä»¶ | åŠŸèƒ½ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| `extract_clip_features.py` | CLIPç‰¹å¾æå– | book_metadata.json | clip_features.npy |
| `build_semantic_graph.py` | Faissæ„å»ºè¯­ä¹‰å›¾ | clip_features.npy | semantic_graph.npz |
| `dual_graph_model.py` | åŒå›¾LightGCNæ¨¡å‹ | - | æ¨¡å‹ç±» |
| `dual_graph_dataloader.py` | æ•°æ®åŠ è½½å™¨ | - | æ•°æ®åŠ è½½å™¨ç±» |
| `train_dual_graph.py` | è®­ç»ƒè„šæœ¬ | å›¾+æ•°æ® | æ¨¡å‹æƒé‡ |
| `run_phase1.py` | ç«¯åˆ°ç«¯Pipeline | - | å®Œæ•´æµç¨‹ |
| `analyze_semantic_graph.py` | è¯­ä¹‰å›¾åˆ†æ | semantic_graph.npz | ç»Ÿè®¡+å¯è§†åŒ– |

### è¾…åŠ©æ–‡ä»¶

- `quick_test.sh`: å¿«é€Ÿæµ‹è¯•è„šæœ¬
- `README_PHASE1.md`: è¯¦ç»†æ–‡æ¡£
- `QUICKSTART.md`: æœ¬æ–‡ä»¶

---

## ğŸ”„ æ ‡å‡†å·¥ä½œæµ

### Step 0: æ£€æŸ¥æ•°æ®

```bash
cd /home/chuc0007/reccase/LightGCN-PyTorch/data/amazon-book

# ç¡®ä¿å­˜åœ¨ä»¥ä¸‹æ–‡ä»¶
ls -lh train.txt test.txt item_list.txt book_metadata.json

# å¦‚æœç¼ºå°‘book_metadata.jsonï¼Œè¿è¡Œï¼š
cd ../../code
python fetch_book_metadata.py
```

### Step 1: æå–CLIPç‰¹å¾ï¼ˆçº¦5-10åˆ†é’Ÿï¼‰

```bash
cd /home/chuc0007/reccase/LightGCN-PyTorch/code

python extract_clip_features.py \
  --data_path ../data/amazon-book \
  --batch_size 32
```

**è¾“å‡ºæ£€æŸ¥**ï¼š
```bash
ls -lh ../data/amazon-book/clip_features.npy
# åº”è¯¥çœ‹åˆ° ~400MB æ–‡ä»¶
```

### Step 2: æ„å»ºè¯­ä¹‰å›¾ï¼ˆçº¦1-2åˆ†é’Ÿï¼‰

```bash
python build_semantic_graph.py \
  --data_path ../data/amazon-book \
  --k 10 \
  --method knn \
  --normalize symmetric
```

**è¾“å‡ºæ£€æŸ¥**ï¼š
```bash
ls -lh ../data/amazon-book/semantic_graph.npz
# åº”è¯¥çœ‹åˆ° ~å‡ åMB æ–‡ä»¶
```

**éªŒè¯å›¾è´¨é‡**ï¼š
```bash
python analyze_semantic_graph.py \
  --data_path ../data/amazon-book \
  --n_examples 5 \
  --plot
```

### Step 3: è®­ç»ƒæ¨¡å‹ï¼ˆçº¦30-60åˆ†é’Ÿï¼Œ100 epochsï¼‰

```bash
python train_dual_graph.py \
  --dataset amazon-book \
  --path ../data/amazon-book \
  --epochs 100 \
  --recdim 64 \
  --layer 3 \
  --use_semantic_graph 1 \
  --semantic_weight 0.5 \
  --semantic_layers 2 \
  --tensorboard 1
```

**ç›‘æ§è®­ç»ƒ**ï¼š
```bash
# å¦å¼€ä¸€ä¸ªç»ˆç«¯
cd /home/chuc0007/reccase/LightGCN-PyTorch/code
tensorboard --logdir runs
# æµè§ˆå™¨æ‰“å¼€ http://localhost:6006
```

---

## ğŸ¯ å¸¸ç”¨å‘½ä»¤

### 1. å®Œæ•´Pipelineï¼ˆæ¨èæ–°æ‰‹ï¼‰

```bash
# ä¸€é”®è¿è¡Œæ‰€æœ‰æ­¥éª¤
python run_phase1.py --dataset amazon-book --epochs 100

# è·³è¿‡å·²å®Œæˆçš„æ­¥éª¤
python run_phase1.py --skip_feature_extraction --skip_graph_building
```

### 2. è¶…å‚æ•°å®éªŒ

```bash
# å®éªŒ1: ä¸åŒkå€¼
python run_phase1.py --k 5 --comment "k5"
python run_phase1.py --k 20 --comment "k20" --skip_feature_extraction

# å®éªŒ2: ä¸åŒè¯­ä¹‰æƒé‡
python run_phase1.py --semantic_weight 0.3 --skip_feature_extraction --skip_graph_building
python run_phase1.py --semantic_weight 0.7 --skip_feature_extraction --skip_graph_building

# å®éªŒ3: æ›´å¤§çš„åµŒå…¥ç»´åº¦
python run_phase1.py --embed_dim 128 --skip_feature_extraction --skip_graph_building
```

### 3. å¯¹æ¯”å®éªŒ

```bash
# Baseline: çº¯ååŒè¿‡æ»¤ï¼ˆä¸ç”¨è¯­ä¹‰å›¾ï¼‰
python train_dual_graph.py \
  --dataset amazon-book \
  --path ../data/amazon-book \
  --use_semantic_graph 0 \
  --epochs 100 \
  --comment "baseline-no-semantic"

# Dual-Graph: ä½¿ç”¨è¯­ä¹‰å›¾
python train_dual_graph.py \
  --dataset amazon-book \
  --path ../data/amazon-book \
  --use_semantic_graph 1 \
  --semantic_weight 0.5 \
  --epochs 100 \
  --comment "dual-graph-sw0.5"
```

---

## ğŸ“Š ç»“æœæŸ¥çœ‹

### è®­ç»ƒæ—¥å¿—

```bash
# æŸ¥çœ‹æœ€æ–°è®­ç»ƒæ—¥å¿—
tail -f /home/chuc0007/reccase/LightGCN-PyTorch/code/runs/*/events.out.tfevents.*

# æˆ–ä½¿ç”¨TensorBoard
tensorboard --logdir code/runs
```

### æ¨¡å‹æƒé‡

```bash
ls -lh /home/chuc0007/reccase/LightGCN-PyTorch/code/checkpoints/
# dual-lgn-amazon-book-64.pth.tar       # æœ€æ–°æ¨¡å‹
# dual-lgn-amazon-book-64_best.pth.tar  # æœ€ä½³æ¨¡å‹
```

### è¯„ä¼°æŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¼šè¾“å‡ºï¼š
- **Recall@20**: åœ¨top-20æ¨èä¸­å‘½ä¸­æµ‹è¯•é›†çš„æ¯”ä¾‹
- **Precision@20**: top-20æ¨èçš„ç²¾ç¡®ç‡
- **NDCG@20**: è€ƒè™‘æ’åºè´¨é‡çš„æŒ‡æ ‡

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: ImportError: No module named 'transformers'

```bash
pip install transformers torch torchvision
```

### Q2: CUDA out of memory

```bash
# å‡å°batch size
python extract_clip_features.py --batch_size 16

# æˆ–ä½¿ç”¨CPU
export CUDA_VISIBLE_DEVICES=""
```

### Q3: Faisså®‰è£…é—®é¢˜

```bash
# CPUç‰ˆæœ¬ï¼ˆé€šç”¨ï¼‰
pip install faiss-cpu

# GPUç‰ˆæœ¬ï¼ˆéœ€è¦CUDAï¼‰
pip install faiss-gpu
```

### Q4: æ¨¡å‹è®­ç»ƒå¾ˆæ…¢

```bash
# æ£€æŸ¥æ˜¯å¦ä½¿ç”¨GPU
python -c "import torch; print(torch.cuda.is_available())"

# å¦‚æœè¿”å›Falseï¼Œæ£€æŸ¥CUDAå®‰è£…
nvidia-smi
```

### Q5: book_metadata.jsonä¸å­˜åœ¨

```bash
cd code
python fetch_book_metadata.py
# éœ€è¦ç­‰å¾…APIè°ƒç”¨ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ
```

---

## ğŸ“ˆ æ€§èƒ½è°ƒä¼˜

### æ¨èçš„å®éªŒé¡ºåº

1. **Baseline**ï¼ˆæ— è¯­ä¹‰å›¾ï¼‰
   ```bash
   python train_dual_graph.py --use_semantic_graph 0
   ```

2. **kå€¼è°ƒä¼˜**ï¼ˆå›¾å¯†åº¦ï¼‰
   ```bash
   for k in 5 10 20 50; do
     python build_semantic_graph.py --k $k --output_name semantic_graph_k${k}.npz
     python train_dual_graph.py --semantic_graph_file semantic_graph_k${k}.npz --comment k${k}
   done
   ```

3. **æƒé‡è°ƒä¼˜**ï¼ˆCF vs è¯­ä¹‰å¹³è¡¡ï¼‰
   ```bash
   for alpha in 0.1 0.3 0.5 0.7; do
     python train_dual_graph.py --semantic_weight $alpha --comment sw${alpha}
   done
   ```

4. **æ¶æ„è°ƒä¼˜**ï¼ˆå±‚æ•°ã€ç»´åº¦ï¼‰
   ```bash
   python train_dual_graph.py --layer 4 --semantic_layers 3 --recdim 128
   ```

### é¢„æœŸæ€§èƒ½æå‡

ç›¸æ¯”baseline LightGCNï¼š
- âœ… å†·å¯åŠ¨ç‰©å“ï¼š+10-20% Recall
- âœ… æ•´ä½“Recall@20ï¼š+2-5%
- âœ… é•¿å°¾è¦†ç›–ç‡æå‡

---

## ğŸ”¬ æ•°æ®é›†ç»Ÿè®¡

Amazon-Bookæ•°æ®é›†ï¼ˆå½“å‰ï¼‰ï¼š
- ç”¨æˆ·æ•°ï¼š52,643
- ç‰©å“æ•°ï¼š91,599
- è®­ç»ƒäº¤äº’ï¼š2,380,730
- æµ‹è¯•äº¤äº’ï¼š238,085
- ç¨€ç–åº¦ï¼š0.0495%

---

## ğŸ“š è¿›é˜¶èµ„æº

- è¯¦ç»†æ–‡æ¡£ï¼š`README_PHASE1.md`
- åŸç‰ˆLightGCNä»£ç ï¼š`code/main.py`
- è¯­ä¹‰å›¾åˆ†æï¼š`python analyze_semantic_graph.py --help`

---

## ğŸ’¡ å°è´´å£«

1. **é¦–æ¬¡è¿è¡Œ**ï¼šä½¿ç”¨`quick_test.sh`å¿«é€ŸéªŒè¯ç¯å¢ƒ
2. **GPUåŠ é€Ÿ**ï¼šç¡®ä¿å®‰è£…`faiss-gpu`å’Œ`torch-cuda`
3. **ç£ç›˜ç©ºé—´**ï¼šç¡®ä¿æœ‰è‡³å°‘5GBç©ºé—²ç©ºé—´
4. **å†…å­˜è¦æ±‚**ï¼šå»ºè®®è‡³å°‘16GB RAM
5. **ä¿å­˜å®éªŒ**ï¼šä½¿ç”¨`--comment`å‚æ•°æ ‡è®°ä¸åŒå®éªŒ

---

## ğŸ†˜ è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹å„è„šæœ¬çš„å¸®åŠ©
python extract_clip_features.py --help
python build_semantic_graph.py --help
python train_dual_graph.py --help
python run_phase1.py --help
```

---

**ç¥å®éªŒé¡ºåˆ©ï¼ğŸ‰**
